{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021BF3C80790> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021BF3C826E0> root_client=<openai.OpenAI object at 0x0000021BF0EE91B0> root_async_client=<openai.AsyncOpenAI object at 0x0000021BF3C807F0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "#Importing LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence that involves creating models capable of generating new content. This content can include text, images, music, videos, and more, based on the data the models have been trained on. The underlying technology often involves advanced machine learning techniques, particularly neural networks and deep learning.\\n\\nSome of the most typical applications and models in generative AI include:\\n\\n1. **Text Generation**: Models like OpenAI's GPT (Generative Pre-trained Transformer) can create coherent and contextually relevant text that can be used in chatbots, content creation, and more.\\n\\n2. **Image Generation**: GANs (Generative Adversarial Networks) and diffusion models can generate realistic images and artworks from textual descriptions or other images. Applications include creating art, enhancing photographs, and even generating deepfakes.\\n\\n3. **Music and Audio**: Algorithms can compose music or generate audio effects, producing original pieces or enhancing existing ones.\\n\\n4. **Video and Animation**: AI models can create new videos, animate images, or even generate special effects for film production.\\n\\n5. **3D Models and Environments**: Generative AI can be used to design 3D objects and environments, useful in gaming, virtual reality, and simulations.\\n\\nGenerative AI models are trained on large datasets and learn the patterns within the data, enabling them to generate new instances that preserve desirable characteristics. Despite their creative potential, these models also pose challenges and concerns, such as ethical considerations around content authenticity, intellectual property rights, and potential misuse.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 313, 'prompt_tokens': 13, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_8adc83c802', 'finish_reason': 'stop', 'logprobs': None} id='run-72f8c06a-1af2-4691-96c3-c6cf27a34eb8-0' usage_metadata={'input_tokens': 13, 'output_tokens': 313, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a suite of developer tools designed by LangChain to facilitate the creation of robust and effective applications that utilize large language models (LLMs). It helps developers evaluate, test, and debug their LLM-powered applications. Key features of Langsmith include observability features to track and measure application performance, testing frameworks to ensure reliability, and tools for fine-tuning and optimizing model outputs. By using Langsmith, developers can enhance the performance and reliability of their LLM applications, making them more adaptable and functional in various use cases.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 33, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None} id='run-aac35b2b-6dad-4dda-a714-a75b1c7d78a2-0' usage_metadata={'input_tokens': 33, 'output_tokens': 108, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed by LangChain, designed to enhance the development and deployment of AI applications. It focuses on improving the reliability and evaluation of these applications by providing robust tools for monitoring, testing, and tracing. Langsmith allows developers to track how AI models perform in real-world scenarios, analyze their outputs, and refine their applications accordingly. It is particularly useful for applications built using LangChain, a framework for creating applications powered by large language models (LLMs) and other AI components. Langsmith helps developers ensure their AI applications perform as expected and meet the desired quality standards.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
